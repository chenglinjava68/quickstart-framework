1、Java线程的5种状态及切换
2、java进程和Linux线程的关系
3、多线程概念：线程同步（两种锁、特殊变量volatile、线程变量ThreadLocal、并发工具类）、线程间通信、线程死锁、线程控制（挂起、停止和恢复）
4、Unsafe类的使用
5、java线程的创建和分类
6、Linux进程间通信
7、线程池：查看ThreadPool.md
8、多线程，到底该设置多少个线程？
  多线程效率不一定高于单线程，因为线程切换（时间、空间等）
  多线程并发目的：提升CPU利用率，因为实际应用处理涉及网络IO、磁盘IO、计算型CPU，导致CPU空闲时间过长，因为等待文件操作，网络操作，数据库操作等
  系统吞吐量（性能）几个重要参数：QPS（TPS）、并发数、响应时间
  设置：
  最佳线程数目 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目
  CPU密集型：操作内存处理的业务：CPU核数 + 1 或者 CPU核数*2
  IO密集型：文件操作，网络操作，数据库操作：CPU核数*N（N=10等，根据实际情况测试）
9、
10、
11、
12、
13、
14、
15、


---------------------------------------------------------------------------------------------------------------------


在多线程编程时，你需要了解以下几个概念：
1、线程同步：synchronized关键字、重入锁ReentrantLock类、特殊域变量(volatile)、CAS变量、并发工具类（信号量）、线程变量ThreadLocal
2、线程间通信：wait+notify/notifyAll、Condition中await+signal/signalAll、锁机制、共享对象（内存或文件、信号量）、Exchanger数据交换
3、线程死锁：
	死锁是指多个线程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。
	死锁产生的必要条件：互斥、不可剥夺、请求保持、循环等待，
	解决：加锁顺序、加锁时限、死锁检测
4、线程控制：挂起、停止和恢复：线程方法、锁（synchronized关键字、重入锁ReentrantLock类）、wait、Condition中的await
//挂起线程
t.suspend();
//恢复线程
t.resume();



---------------------------------------------------------------------------------------------------------------------


在java中主要的通信方式有以下几种： 
1、socket通信 
2、同步：RMI（远程方法调用） 或者 RPC
3、异步：消息队列（第三方框架Kafka，ActiveMQ等） 
4、共享对象：内存、文件共享，文件锁（一个进程向文件中写文件，一个负责读文件） 
5、JMX（java management extensions）java扩展管理 
6、信号 、信号量


在操作系统中进程和线程的区别：
　　进程：每个进程都有独立的代码和数据空间（进程上下文），进程间的切换会有较大的开销，一个进程包含1--n个线程。（进程是资源分配的最小单位）
　　线程：同一类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器(PC)，线程切换开销小。（线程是cpu调度的最小单位）
　　线程和进程一样分为五个阶段：创建、就绪、运行、阻塞、终止。
　　多进程是指操作系统能同时运行多个任务（程序）。
　　多线程是指在同一程序中有多个顺序流在执行。

---------------------------------------------------------------------------------------------------------------------

在java中要想实现多线程，有两种手段，一种是继续Thread类，另外一种是实现Runable接口.(其实准确来讲，应该有三种，还有一种是实现Callable接口，并与Future、线程池结合使用，

注意：start()方法的调用后并不是立即执行多线程代码，而是使得该线程变为可运行态（Runnable），什么时候运行是由操作系统决定的。
从程序运行的结果可以发现，多线程程序是乱序执行。因此，只有乱序执行的代码才有必要设计为多线程。
Thread.sleep()方法调用目的是不让当前线程独自霸占该进程所获取的CPU资源，以留出一定时间给其他线程执行的机会。
实际上所有的多线程代码执行顺序都是不确定的，每次执行的结果都是随机的。
但是start方法重复调用的话，会出现java.lang.IllegalThreadStateException异常。


Thread2类通过实现Runnable接口，使得该类有了多线程类的特征。run（）方法是多线程程序的一个约定。所有的多线程代码都在run方法里面。Thread类实际上也是实现了Runnable接口的类。
在启动的多线程的时候，需要先通过Thread类的构造方法Thread(Runnable target) 构造出对象，然后调用Thread对象的start()方法来运行多线程代码。
实际上所有的多线程代码都是通过运行Thread的start()方法来运行的。因此，不管是扩展Thread类还是实现Runnable接口来实现多线程，最终还是通过Thread的对象的API来控制线程的，熟悉Thread类的API是进行多线程编程的基础。


Thread和Runnable的区别
如果一个类继承Thread，则不适合资源共享。但是如果实现了Runable接口的话，则很容易的实现资源共享。
总结：
实现Runnable接口比继承Thread类所具有的优势：
1）：适合多个相同的程序代码的线程去处理同一个资源
2）：可以避免java中的单继承的限制
3）：增加程序的健壮性，代码可以被多个线程共享，代码和数据独立
4）：线程池只能放入实现Runable或callable类线程，不能直接放入继承Thread的类
 

提醒一下大家：main方法其实也是一个线程。在java中所以的线程都是同时启动的，至于什么时候，哪个先执行，完全看谁先得到CPU的资源。
在java中，每次程序运行至少启动2个线程。一个是main线程，一个是垃圾收集线程。因为每当使用java命令执行一个类的时候，实际上都会启动一个ＪＶＭ，每一个JVM实习在就是在操作系统中启动了一个进程。




---------------------------------------------------------------------------------------------------------------------

Unsafe类：
https://www.cnblogs.com/pkufork/p/java_unsafe.html
https://www.cnblogs.com/mickole/articles/3757278.html
http://www.importnew.com/14511.html
https://blog.csdn.net/zhxdick/article/details/52003123

线程池、队列的超时等待：UNSAFE.park(false, nanos)、unpark，线程--》队列的poll超时--》Condition的await---》LockSupport.park---UNSAFE.park
nio的DirectByteBuffer内存分配：unsafe.allocateMemory(size)，freeMemory(long)
原子类的cas方法：unsafe.compareAndSwapInt方法、unsafe.compareAndSwapLong

1、通过Unsafe类可以分配内存，可以释放内存；
类中提供的3个本地方法allocateMemory、reallocateMemory、freeMemory分别用于分配内存，扩充内存和释放内存，与C语言中的3个方法对应。
2、CAS操作
是通过compareAndSwapXXX方法实现的
3、挂起与恢复
将一个线程进行挂起是通过park方法实现的，调用 park后，线程将一直阻塞直到超时或者中断等条件出现。unpark可以终止一个挂起的线程，使其恢复正常。整个并发框架中对线程的挂起操作被封装在 LockSupport类中，LockSupport类中有各种版本pack方法，但最终都调用了Unsafe.park()方法。
4、数组操作。
这部分包括了arrayBaseOffset（获取数组第一个元素的偏移地址）、arrayIndexScale（获取数组中元素的增量地址）等方法。arrayBaseOffset与arrayIndexScale配合起来使用，就可以定位数组中每个元素在内存中的位置。
由于Java的数组最大值为Integer.MAX_VALUE，使用Unsafe类的内存分配方法可以实现超大数组。实际上这样的数据就可以认为是C数组，因此需要注意在合适的时间释放内存。
---------------------------------------------------------------------------------------------------------------------


Java线程的5种状态及切换(透彻讲解)
https://www.cnblogs.com/nwnu-daizh/p/8036156.html
http://blog.csdn.net/pange1991/article/details/53860651


新建-->就绪-->运行-->死亡（start(),获取cpu时间片,run/main结束）
运行-->阻塞-->就绪-->运行（sleep、t2.join、等用户输入，3中阻塞条件结束，获取cpu时间片）
运行-->等待队列-->锁池队列-->就绪（wait()+notify/notifyAll、synchronized(obj) ）
运行-->就绪（yield()、时间片用完）

![线程状态转换](https://github.com/youngzil/notes/tree/master/document/docs/interview/image/threadstatuschange.png "ReferencePicture")

在调用sleep()方法的过程中，线程不会释放对象锁。
而当调用wait()方法的时候，线程会放弃对象锁，让出cpu该其他线程，进入等待此对象的等待锁定池，只有针对此对象调用notify()方法后本线程才进入对象锁定池准备


---------------------------------------------------------------------------------------------------------------------
https://www.jianshu.com/p/2fff42a9dfcf
多线程，到底该设置多少个线程？

多线程效率不一定高于单线程，因为线程切换（时间、空间等）
多线程并发目的：提升CPU利用率，因为实际应用处理涉及网络IO、磁盘IO、计算型CPU，导致CPU空闲时间过长，因为等待文件操作，网络操作，数据库操作等
系统吞吐量（性能）几个重要参数：QPS（TPS）、并发数、响应时间
设置：
最佳线程数目 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目
CPU密集型：操作内存处理的业务：CPU核数 + 1 或者 CPU核数*2
IO密集型：文件操作，网络操作，数据库操作：CPU核数*N（N=10等，根据实际情况测试）



线程的执行，是由CPU进行调度的，一个CPU在同一时刻只会执行一个线程，我们看上去的线程A 和 线程B并发执行。

为了让用户感觉这些任务正在同时进行，操作系统利用了时间片轮转的方式，CPU给每个任务都服务一定的时间，然后把当前任务的状态保存下来，在加载下一任务的状态后，继续服务下一任务。任务的状态保存及再加载，这段过程就叫做上下文切换。

上下文切换过程是需要时间的；现在我们来看一下上面的问题，小伙伴们再看一下是哪个方案快呢？是不是有些小伙伴们会说方案一，因为不需要线程切换；方案二需要来回切换这两个线程，耗时会多点。

常规的请求流程；我们看一下整个过程涉及到什么计算机处理。
1、网络请求----->网络IO
2、解析请求----->CPU
3、请求数据库----->网络IO
4、MySQL查询数据----->磁盘IO
5、MySQL返回数据----->网络IO
6、数据处理----->CPU
7、返回数据给用户----->网络IO

在真实业务中我们不单单会涉及CPU计算，还有网络IO和磁盘IO处理，这些处理是非常耗时的。如果一个线程整个流程是上图的流程，真正涉及到CPU的只有2个节点，其他的节点都是IO处理，那么线程在做IO处理的时候，CPU就空闲出来了，CPU的利用率就不高。

小伙伴们现在知道多线程的用处了吧，对，就是为了提升CPU利用率。


TPS：Transactions Per Second（每秒传输的事物处理个数），即服务器每秒处理的事务数。
QPS：每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。
吞吐量：一个系统的吞吐量（承压能力）与request对CPU的消耗、外部接口、IO等等紧密关联。单个reqeust 对CPU消耗越高，外部系统接口、IO影响速度越慢，系统吞吐能力越低，反之越高。

系统吞吐量（性能）几个重要参数：QPS（TPS）、并发数、响应时间
QPS（TPS）：每秒钟request/事务 数量
并发数： 系统同时处理的request/事务数
响应时间： 一般取平均响应时间

衡量系统性能如何，主要指标系统的（QPS/TPS）
QPS/TPS：每秒能够处理请求/事务的数量
并发数：系统同时处理的请求/事务的数量
响应时间：就是平均处理一个请求/事务需要时长

QPS（TPS）= 并发数/平均响应时间 或者 并发数 = QPS*平均响应时间

上面公式代表并发数越大，QPS就越大；所以很多人就会以为调大线程池，并发数就会大，也会提升QPS，所以才会出现一开始前言所说的，大多数人的误区。
其实QPS还跟响应时间成反比，响应时间越大，QPS就会越小。
虽然并发数调大了，就会提升QPS，但线程数也会影响响应时间，因为上面我们也提到了上下文切换的问题，那怎么设置线程数的呢？

最佳线程数目 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目

备注这个公式也是前辈们分享的，当然之前看了淘宝前台系统优化实践的文章，和上面的公式很类似，不过在CPU数目那边，他们更细化了，上面的公式只是参考。不过不管什么公式，最终还是在生产环境中运行后，再优化调整。

我们继续上面的任务，我们的服务器CPU核数为4核，一个任务线程cpu耗时为20ms，线程等待（网络IO、磁盘IO）耗时80ms，那最佳线程数目：( 80 + 20 )/20 * 4 = 20。也就是设置20个线程数最佳。
从这个公式上面我们就得出，线程的等待时间越大，线程数就要设置越大，这个正好符合我们上面的分析，可提升CPU利用率。那从另一个角度上面说，线程数设置多大，是根据我们自身的业务的，需要自己去压力测试，设置一个合理的数值。

1、CPU密集型：操作内存处理的业务，一般线程数设置为：CPU核数 + 1 或者 CPU核数*2。核数为4的话，一般设置 5 或 8
2、IO密集型：文件操作，网络操作，数据库操作，一般线程设置为：cpu核数 / (1-0.9)，核数为4的话，一般设置 40

---------------------------------------------------------------------------------------------------------------------

参考
https://www.cnblogs.com/yjd_hycf_space/p/7526608.html
https://blog.csdn.net/ls5718/article/details/51896159





